{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "##### - It always seems impossible until it's done\n",
    "\n",
    "___\n",
    "\n",
    "In this blog, we will discuss the workflow of a Machine learning project this includes all the steps required to build the proper machine learning project from scratch.\n",
    "\n",
    "We will also go over \n",
    "___\n",
    "\n",
    "#### data pre-processing\n",
    "\n",
    "#### data cleaning\n",
    "\n",
    "#### feature exploration\n",
    "\n",
    "#### feature engineering  \n",
    "____\n",
    "And show the impact that it has on Machine Learning Model Performance. We will also cover a couple of the pre-modelling steps that can help to improve the model performance.\n",
    "\n",
    "Python Libraries that would be need to achieve the task:\n",
    " 1. Numpy\n",
    " 2. Pandas\n",
    " 3. Sci-kit Learn\n",
    " 4. Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the machine learning workflow\n",
    "___\n",
    "We can define the machine learning workflow in 3 stages.\n",
    "\n",
    "1) Gathering data\n",
    "\n",
    "2) Data pre-processing\n",
    "\n",
    "3) Researching the model that will be best for the type of data\n",
    "\n",
    "4) Training and testing the model\n",
    "\n",
    "5) Evaluation\n",
    "\n",
    "Okay but first let’s start from the basics\n",
    "\n",
    "\n",
    "## What is the machine learning Model?\n",
    "___\n",
    "\n",
    "The machine learning model is nothing but a piece of code; an engineer or data scientist makes it smart through training with data. \n",
    "\n",
    "So, **if you give garbage to the model, you will get garbage in return**, i.e. the trained model will provide false or wrong predictions.\n",
    "<img src=\"https://static.toiimg.com/img/64975832/Master.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Gathering Data\n",
    "___\n",
    "\n",
    "The process of gathering data depends on the type of project we desire to make, if we want to make an ML project that uses real-time data, then we can build an IoT system that using different sensors data.\n",
    "\n",
    "The data set can be collected from various sources such as a file, database, sensor and many other such sources but the collected data cannot be used directly for performing the analysis process as there might be a lot of missing data, extremely large values, unorganized text data or noisy data. \n",
    "\n",
    "Therefore, to solve this problem Data Preparation is done\n",
    "<img src=\"https://www.cdc.gov/ncbddd/hemophilia/communitycounts/images/data-icon.png\" width=\"150\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Data pre-processing\n",
    "___\n",
    "\n",
    "Data pre-processing is one of the most important steps in machine learning. It is the most important step that helps in building machine learning models more accurately. In machine learning, there is an 80/20 rule. Every data scientist should spend 80% time for data pre-processing and 20% time to actually perform the analysis.\n",
    "\n",
    "<img src=\"https://seoespecialista.com/wp-content/uploads/2017/02/Strutruced-data.png\" width=\"150\" />\n",
    "\n",
    "### What is data pre-processing?\n",
    "___\n",
    "\n",
    "Data pre-processing is a process of cleaning the raw data i.e. the data is collected in the real world and is converted to a clean data set. In other words, whenever the data is gathered from different sources it is collected in a raw format and this data isn’t feasible for the analysis.\n",
    "\n",
    "Therefore, certain steps are executed to convert the data into a small clean data set, this part of the process is called as data pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we need it?\n",
    "___\n",
    "\n",
    "As we know that data pre-processing is a process of cleaning the raw data into clean data, so that can be used to train the model. So, we definitely need data pre-processing to achieve good results from the applied model in machine learning and deep learning projects.\n",
    "\n",
    "Most of the real-world data is messy, some of these types of data are:\n",
    "\n",
    "####  1. Missing data:\n",
    "Missing data can be found when it is not continuously created or due to technical issues in the application (IOT system).\n",
    "\n",
    "#### 2. Noisy data: \n",
    "This type of data is also called outliners, this can occur due to human errors (human manually gathering the data) or some technical problem of the device at the time of collection of data.\n",
    "\n",
    "#### 3. Inconsistent data: \n",
    "This type of data might be collected due to human errors (mistakes with the name or values) or duplication of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three Types of Data\n",
    "___\n",
    "\n",
    "*1. Numeric e.g. income, age*\n",
    "\n",
    "*2. Categorical e.g. gender, nationality*\n",
    "\n",
    "*3. Ordinal e.g. low/medium/high*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can data pre-processing be performed?\n",
    "___  \n",
    "\n",
    "\n",
    "<img src=\"https://medorder.co.uk/wp-content/uploads/2017/04/7445670.jpg\" width=\"150\" />\n",
    "\n",
    "These are some of the basic pre — processing techniques that can be used to convert raw data.\n",
    "\n",
    "##### 1. Conversion of data: \n",
    "As we know that Machine Learning models can only handle numeric features, hence categorical and ordinal data must be somehow converted into numeric features.\n",
    "\n",
    "##### 2. Ignoring the missing values: \n",
    "Whenever we encounter missing data in the data set then we can remove the row or column of data depending on our need. This method is known to be efficient but it shouldn’t be performed if there are a lot of missing values in the dataset.\n",
    "\n",
    "##### 3. Filling the missing values:\n",
    "Whenever we encounter missing data in the data set then we can fill the missing data manually, most commonly the mean, median or highest frequency value is used.\n",
    "\n",
    "##### 4. Machine learning:\n",
    "If we have some missing data then we can predict what data shall be present at the empty position by using the existing data.\n",
    "\n",
    "##### 5. Outliers detection: \n",
    "There are some error data that might be present in our data set that deviates drastically from other observations in a data set. [Example: human weight = 800 Kg; due to mistyping of extra 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3. Researching the model \n",
    "### that will be best for the type of data\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
